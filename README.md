## DA6401-Assignment-1
Implementing a FeedForward Neural Network with Backpropagation from scratch alongwith few optimizers and loss functions on Fashion-MNIST data.

Optimizers implemented:
SGD - Stochastic Gradient Descent
Momentum - Momentum SGD
NesterovAG - Nesterov Accelerated Gradient
RMSProp - Root Mean Square Propagation
Adam - Adaptive Moment Estimation
Nadam - Nesterov Adaptive Moment Estimation

Loss functions implemented:
Cross Entropy
Mean Squared Error

#How to run?
''' bash
python train.py -wp <wandb_project_name> -we <wandb_entity_name>
'''

