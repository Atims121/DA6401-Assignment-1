## DA6401-Assignment-1
Implementing a FeedForward Neural Network with Backpropagation from scratch alongwith few optimizers and loss functions on Fashion-MNIST data.

#Optimizers implemented: <br>
SGD - Stochastic Gradient Descent <br>
Momentum - Momentum SGD <br>
NesterovAG - Nesterov Accelerated Gradient <br>
RMSProp - Root Mean Square Propagation<br>
Adam - Adaptive Moment Estimation<br>
Nadam - Nesterov Adaptive Moment Estimation<br>

#Loss functions implemented:
Cross Entropy<br>
Mean Squared Error<br>

#How to run? <br>
''' bash
python train.py -wp <wandb_project_name> -we <wandb_entity_name>
'''

